version: "3.2"

networks:
  default:
    external:
      name: merlin_net

volumes:
  datavolume:
    driver: local
    driver_opts:
      type: cifs
      device: //10.1.70.252/merlin
      o: username=,password=

services:
  #HDFS and Spark Name Node Service
  namenode:
    image: 10.1.70.193:5000/merlin-hadoop-namenode
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager
  #  volumes:
  #    - $PWD/../share:/share
    volumes:
      - datavolume:/mnt/merlin
    ports:
      - "8088:8088"
      - "50070:50070"
      - "9000:9000"
      - "8042:8042"
      - "8020:8020"

  #HDFS Data Nodes
  datanode:
    image: 10.1.70.193:5000/merlin-hadoop-base
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
  #Hadoop/spark workers on Yarn
  sparkworker:
    image: 10.1.70.193:5000/merlin-hadoop-base
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
    volumes:
          - datavolume:/mnt/merlin
    command: "/root/hadoop_entrypoint.sh -spark_worker"
  #Hadoop/spark staging server
  stagingserver:
    image: 10.1.70.193:5000/merlin-hadoop-base
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    volumes:
          - datavolume:/mnt/merlin
    command: "/root/hadoop_entrypoint.sh"
