version: "3.2"

networks:
  default:
    external:
      name: merlin_net

volumes:
  datavolume:
    driver: local
    driver_opts:
      type: cifs
      device: //10.1.70.252/merlin
      o: username=,password=

configs:
  core-site:
    file: ./configs/core-site.xml
  hdfs-site:
    file: ./configs/hdfs-site.xml
  hive-site:
    file: ./configs/hive-site.xml
  mapred-site:
    file: ./configs/mapred-site.xml
  spark-defaults:
    file: ./configs/spark-defaults.conf
  yarn-site:
    file: ./configs/yarn-site.xml

services:
  #HDFS and Spark Name Node Service
  namenode:
    image: 10.1.70.193:5000/merlin-hadoop-namenode
    configs:
      - source: hive-site
        target: /usr/local/hive/conf/hive-site.xml

      - source: hive-site
        target: /usr/local/spark/conf/hive-site.xml
      - source: mapred-site
        target: /usr/local/spark/conf/mapred-site.xml
      - source: spark-defaults
        target: /usr/local/spark/conf/spark-defaults.conf
      - source: yarn-site
        target: /usr/local/spark/conf/yarn-site.xml

      - source: core-site
        target: /usr/local/hadoop/conf/core-site.xml
      - source: hdfs-site
        target: /usr/local/hadoop/conf/hdfs-site.xml
      - source: mapred-site
        target: /usr/local/hadoop/conf/mapred-site.xml
      - source: yarn-site
        target: /usr/local/hadoop/conf/yarn-site.xml
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager
  #  volumes:
  #    - $PWD/../share:/share
    volumes:
      - datavolume:/mnt/merlin
    ports:
      - "8088:8088"
      - "50070:50070"
      - "9000:9000"
      - "8042:8042"
      - "8020:8020"

  #HDFS Data Nodes
  datanode:
    image: 10.1.70.193:5000/merlin-hadoop-base
    configs:
      - source: hive-site
        target: /usr/local/hive/conf/hive-site.xml

      - source: hive-site
        target: /usr/local/spark/conf/hive-site.xml
      - source: mapred-site
        target: /usr/local/spark/conf/mapred-site.xml
      - source: spark-defaults
        target: /usr/local/spark/conf/spark-defaults.conf
      - source: yarn-site
        target: /usr/local/spark/conf/yarn-site.xml

      - source: core-site
        target: /usr/local/hadoop/conf/core-site.xml
      - source: hdfs-site
        target: /usr/local/hadoop/conf/hdfs-site.xml
      - source: mapred-site
        target: /usr/local/hadoop/conf/mapred-site.xml
      - source: yarn-site
        target: /usr/local/hadoop/conf/yarn-site.xml
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
  #Hadoop/spark workers on Yarn
  sparkworker:
    image: 10.1.70.193:5000/merlin-hadoop-base
    configs:
      - source: hive-site
        target: /usr/local/hive/conf/hive-site.xml

      - source: hive-site
        target: /usr/local/spark/conf/hive-site.xml
      - source: mapred-site
        target: /usr/local/spark/conf/mapred-site.xml
      - source: spark-defaults
        target: /usr/local/spark/conf/spark-defaults.conf
      - source: yarn-site
        target: /usr/local/spark/conf/yarn-site.xml

      - source: core-site
        target: /usr/local/hadoop/conf/core-site.xml
      - source: hdfs-site
        target: /usr/local/hadoop/conf/hdfs-site.xml
      - source: mapred-site
        target: /usr/local/hadoop/conf/mapred-site.xml
      - source: yarn-site
        target: /usr/local/hadoop/conf/yarn-site.xml
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
    volumes:
          - datavolume:/mnt/merlin
    command: "/root/hadoop_entrypoint.sh -spark_worker"
  #Hadoop/spark staging server
  stagingserver:
    image: 10.1.70.193:5000/merlin-hadoop-base
    configs:
      - source: hive-site
        target: /usr/local/hive/conf/hive-site.xml

      - source: hive-site
        target: /usr/local/spark/conf/hive-site.xml
      - source: mapred-site
        target: /usr/local/spark/conf/mapred-site.xml
      - source: spark-defaults
        target: /usr/local/spark/conf/spark-defaults.conf
      - source: yarn-site
        target: /usr/local/spark/conf/yarn-site.xml

      - source: core-site
        target: /usr/local/hadoop/conf/core-site.xml
      - source: hdfs-site
        target: /usr/local/hadoop/conf/hdfs-site.xml
      - source: mapred-site
        target: /usr/local/hadoop/conf/mapred-site.xml
      - source: yarn-site
        target: /usr/local/hadoop/conf/yarn-site.xml
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    volumes:
          - datavolume:/mnt/merlin
    command: "/root/hadoop_entrypoint.sh"
